{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57f03a22-aedd-4fdd-ae79-af75722a3dd0",
   "metadata": {},
   "source": [
    "![Callysto.ca Banner](https://github.com/callysto/curriculum-notebooks/blob/master/callysto-notebook-banner-top.jpg?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a711085-097f-460b-b501-b591f2bbc416",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Module 3 Unit 4  - Cleaning and Filtering Data Sets\n",
    "\n",
    "*This section contains tutorials! Get the most out of them by opening a Jupyter notebook in another window and following along. Code snippets provided in the course can be pasted directly into your Jupyter notebook. Review Module 2, Unit 5 for a refresher on creating and opening Jupyter notebooks in Callysto.*\n",
    "\n",
    "The more accurate and representative our data set is, the more useful it is for data analysis. However, data sets often come with errors — mistakes made by people collecting or entering data, or caused by computer glitches when saving, copying, or transmitting data.\n",
    "\n",
    "When doing data science, it's always a good idea to review our data and filter out faulty observations.\n",
    "\n",
    "In this unit, we'll explore ways to:\n",
    "\n",
    "* Select and view particular data in a DataFrame\n",
    "* Add and remove rows\n",
    "* Reorder rows\n",
    "* Modify values\n",
    "* Replace values\n",
    "* Find outliers\n",
    "\n",
    "The activities in this unit use a *coin_df* DataFrame similar to the one we created earlier in the course.\n",
    "\n",
    "Create *coin_df* by running the code below.\n",
    "\n",
    "    from pandas import DataFrame\n",
    "    data = {'name': ['penny', 'nickel', 'dime', 'quarter'],\n",
    "     'value': [1, 5, 10, 25],\n",
    "     'weight': [2.35, 3.95, 1.75, 4.4],\n",
    "     'design': ['Maple Leaves', 'Beaver', 'Schooner', 'Caribou'] }\n",
    "    coin_df = DataFrame( data )\n",
    "    coin_df\n",
    "\n",
    "\n",
    "![coin df](../_images/Module3-Unit4-image.png)\n",
    "\n",
    "*A demonstration of how to show the output of a completed DataFrame, using Python programming. The Python programming used to show the completed DataFrame about the penny, nickel, dime, and quarter was \"coins_df.\"*\n",
    "\n",
    "\n",
    "### 🏁 Activity: Common functions\n",
    "\n",
    "This table provides some common functions and what they look like as a line of code. Try each one out and see what kind of output they produce.\n",
    "\n",
    "| Operation                                         | Description                                                       |\n",
    "|---------------------------------------------------|-------------------------------------------------------------------|\n",
    "| `coin_df['name']`                                | Select (and print out) a column                                    |\n",
    "| `coin_df[['name','weight']]`                     | Select two columns                                                 |\n",
    "| `coin_df.loc[1]`                                 | Select a row                                                       |\n",
    "| `coin_df.loc[1,'name']`                          | Select a single value in row/column                                |\n",
    "| `coin_df.loc[1,'name'] = 'NICKEL'`               | Change a single data point in row/column                           |\n",
    "| `coin_df[coin_df['weight']>3]`                   | Select all the rows where the weight of the coin is greater than 3 |\n",
    "\n",
    "\n",
    "### Adding another row to the DataFrame\n",
    "\n",
    "If we want to expand our data set, we can use the loc command to add a new row and specify its index and values. Let's try that now.\n",
    "\n",
    "Run the code below in your Jupyter notebook to add another row to the coin_df DataFrame.\n",
    "\n",
    "    coin_df.loc[4] = ['50-cent piece', 50, 6.9, 'Coat of Arms']\n",
    "    coin_df\n",
    "    \n",
    "The outcome should look something like this:\n",
    "\n",
    "![coin df 2](../_images/Module3-Unit4-image1.png)\n",
    "\n",
    "*A DataFrame containing data on the value, weight and design of various coins. The first five include 'penny', 'nickel', 'dime', 'quarter', '50-cent piece'. Each row contains information for each of these coins.*\n",
    "\n",
    "In this example, we set the row index for the new coin to be 4, but when adding a row we can actually set it as nearly any unused rational number. For example, we could make the row index 7, 42, 5000, -71, or 3.14592 (pi to the 5th decimal).\n",
    "\n",
    "\n",
    "### Dropping a row from the DataFrame\n",
    "\n",
    "Conversely, if we want to remove some data from our DataFrame, we can use the drop function. For instance, the following line of code will remove the row with index 0.\n",
    "\n",
    "    coin_df.drop(index=0)\n",
    "    \n",
    "![coin df 3](../_images/Module3-Unit4-image2.png)\n",
    "\n",
    "*A DataFrame containing data on the value, weight and design of various coins after the 'penny' row has been removed. The first three include 'nickel', 'dime', 'quarter'. Each row contains information for each of these coins.*\n",
    "\n",
    "Notice that this is actually a new DataFrame with one fewer row than the DataFrame coin_df. If you want to change coin_df itself, use the inplace option:\n",
    "\n",
    "    coin_df.drop(index=0, inplace=True)\n",
    "    \n",
    "    \n",
    "### Reordering rows in the DataFrame\n",
    "\n",
    "Sometimes it's helpful to order rows in a data set according to the data, rather than their default row index number. For example, we might want to display our coin data in alphabetical order.\n",
    "\n",
    "The **reindex** function lets us specify a particular row order.\n",
    "\n",
    "    coin_df.reindex([2,1,0,3])\n",
    "    \n",
    "Try this in your own notebook now. The outcome should look like this:\n",
    "\n",
    "![coin df 4](../_images/Module3-Unit4-image3.png)\n",
    "\n",
    "*Demonstration of sorting coins DataFrame by name, using alphabetical order. Order of rows changes to reflect: data for dime, then data for nickel, then data for penny, then data for quarter. Note that data for 50-cent piece does not appear here.*\n",
    "\n",
    "### Modifying values in the DataFrame\n",
    "\n",
    "Earlier in the course, we explored how to modify an entire column of entries at once by applying a simple mathematical formula, similar to this one:\n",
    "\n",
    "    coin_df['value'] = coin_df['value']/100\n",
    "    coin_df\n",
    "    \n",
    "![coin df 5](../_images/Module3-Unit4-image4.png)\n",
    "\n",
    "*Demonstration of sorting coins DataFrame by weight, in ascending order. The lowest value is 0.01 corresponding to penny, followed by 0.05 corresponding to nickel, followed by 0.10 corresponding to dime, followed by 0.25 corresponding to quarter, followed by 0.50 corresponding to 50-cent piece.*\n",
    "\n",
    "This method is good for a bulk modification to numbers, but what if we want to modify text values, also known as strings?\n",
    "\n",
    "#### 🏷️ Key Term: String\n",
    ">In Python, a string is a specific sequence of characters. Any value in a data set that is not a number is a string, such as a name or label.\n",
    "\n",
    "For this we can use the map command.\n",
    "\n",
    "For example, right now all the text in our DataFrame is lowercase — except for the values under the design column. The following command shows what the text looks like in lower case.\n",
    "\n",
    "    coin_df['design'].map(str.lower)\n",
    "    \n",
    "![coin df 6](../_images/Module3-Unit4-image5.png)\n",
    "\n",
    "*Demonstration of turning all words under the desing column into lower case. Sorted by value. Printed on screen: 0 (row index) maple leaves, 1 (row index) beaver, 2 (row index) schooner, 3 (row index) caribou, 4 (row index) coat of arms. Name of column: design. Type object.*\n",
    "\n",
    "Remember, this doesn’t change the original DataFrame, it just outputs the result. If you are happy with this result, then you can store it back in the DataFrame, like this:\n",
    "\n",
    "    coin_df['design'] = coin_df['design'].map(str.lower)\n",
    "\n",
    "\n",
    "#### Lambda functions (Optional)\n",
    "\n",
    "Lambda functions allow us to use a function as a parameter to another function, like the map function mentioned earlier in the course.\n",
    "\n",
    "For instance, suppose we needed a function that would let us double all the weight values in our data set.\n",
    "\n",
    "We could start by defining a function called *Doubler* and pass it to the map function, like this:\n",
    "\n",
    "    def Doubler(x):\n",
    "        return x+x\n",
    "    coin_df['weight'].map(Doubler)\n",
    "    \n",
    "However, a more succinct way is to represent the Doubler function in the call to map, like this:\n",
    "\n",
    "    coin_df['weight'].map(lambda x: x+x)\n",
    "    \n",
    "\n",
    "So this way, the Doubler function is represented in the **map** function as a parameter, using the form of a lambda notation.\n",
    "\n",
    "We call this type of function an **anonymous function,** because we never define it with a specific name.\n",
    "\n",
    "In a more useful example, we might like to specify a numerical function that converts units for the weights.\n",
    "\n",
    "The lambda function defined via the statement:\n",
    "\n",
    "    lambda x : x*28.35\n",
    "    \n",
    "will convert ounces to grams. We can apply this to the weight column, with the **map** function calling up the lambda function:\n",
    "\n",
    "![coin df 7](../_images/Module3-Unit4-image6.png)\n",
    "\n",
    "*Demonstration of changing the value under weight column for each column using lambda functions. Using the .map() method we can change the weight that appears for each column as follows coins_df['weight'].map(lambda x: x*28.35). This will multiply each value under the 'weight' column by 28.35.*\n",
    "\n",
    "Practice this yourself with this code:\n",
    "\n",
    "    coin_df['weight'].map(lambda x: x*28.35)\n",
    "    \n",
    "#### Replacing values\n",
    "\n",
    "If a value in our DataFrame isn't quite right, we can **replace** it with a new one.\n",
    "\n",
    "For example, the design on a Canadian dime shows a schooner sailing ship. However, most people know it represents a racing ship built in Halifax, Nova Scotia, in the 1920s – *the Bluenose.*\n",
    "\n",
    "![bluenose](../_images/Module3-Unit4-image7.jpeg)\n",
    "\n",
    "*The Bluenose photographed in 1921 by W. R. MacAskill*\n",
    "\n",
    "Let's use the replace function to make the design entry for the dime display as the more familiar Bluenose.\n",
    "\n",
    "    coin_df['design'].replace('Schooner','Bluenose')\n",
    "    \n",
    "![coin df 8](../_images/Module3-Unit4-image8.png)\n",
    "\n",
    "*Demonstration of replacing the word \"Schooner\" for \"Bluenose\" under the desing column in coin_df. This can be done as follows coin_df['design'].replace('Schooner','Bluenose').*\n",
    "\n",
    "This function is particularly useful when there are multiple instances of a word that needs to be replaced.\n",
    "\n",
    "For example, if we wanted to change the word cat to feline in the pets DataFrame we created earlier in the course.\n",
    "##### 🏁 Activity: ?\n",
    "\n",
    "![coin df 9](../_images/Module3-Unit4-image9.png)\n",
    "*Demonstration of replacing the word \"cat\" for \"feline\" under the Species column in pets. This can be done as follows: pets['Species'].replace('cat', 'feline').*\n",
    "\n",
    "The replace function can be applied to both numbers and text.\n",
    "\n",
    "A common use is to replace a **marker value** in a data set, like -999, with the more useful np.nan designation from the NumPy library.\n",
    "\n",
    "    pets['Legs'].replace(-999,np.nan)\n",
    "    \n",
    "#### 🏷️ Key Term: Marker Value\n",
    ">A marker value indicates that something unusual happened when a specific data point was recorded. For example, if a researcher's equipment broke, there might not be data for a specific day. Rather than leaving the entry blank for that day, they might use a clearly identifiable value like -999 to indicate the data point isn't available. We shouldn’t use that value in any calculation of averages or minimum temperatures, so it should be replaced before doing any analysis.\n",
    "\n",
    "#### 🏷️ Key Term: Not a Number (NaN)\n",
    ">Numerical Python, or Numpy, has a special value to represent a data point that is Not A Number or briefly NaN. Rather than storing a special value like -999 to indicate missing data, a NaN indicates no number was recorded here. Python and pandas are smart enough to know that they should not use NaNs in their calculations of averages, maximum values, plotting the data, etc. So they are very handy placeholders for data in a programming environment.\n",
    "\n",
    "\n",
    "### Finding Outliers\n",
    "\n",
    "One way we can find errors is by looking for values that seem unusually high or low compared to the rest of the data set — **outliers.**\n",
    "\n",
    "Many of the mathematical functions we've already explored can help us find and examine outliers in our data.\n",
    "\n",
    "For example, we could use the min and max functions to identify the lowest or highest values in a column.\n",
    "\n",
    "![coin df 10](../_images/Module3-Unit4-image10.png)\n",
    "\n",
    "*Demonstration of computing the maximum age of pets. Using the notation pets['Age (years)'].max() we can obtain the maximum age of pets from the pets DataFrame.*\n",
    "\n",
    "Or, use a mathematical formula to display all the rows with a value that falls below or above a particular threshold.\n",
    "\n",
    "![coin df 11](../_images/Module3-Unit4-image11.png)\n",
    "\n",
    "*Demonstration of subsetting the pets dataframe by the Age column: selecting pets older than 8 years. Subsetting occurs in two stages: first select values under 'Age (years)' column satisfying the condition 'older than 8 years'. We can do that via the command pets['Age (years)'] >8. The second stage is obtaining all column values for pets older than 8 years old. We can do so as follows pets[pets['Age (years)'] >8].*\n",
    "\n",
    "DataFrames come with **idxmax** and **idxmin** functions, which output the index number for the row with the highest or lowest value in the specified column.\n",
    "\n",
    "\n",
    "![coin df 12](../_images/Module3-Unit4-image12.png)\n",
    "\n",
    "*Demonstration of idxmax(), idxmin() to return index of first occurrence of max and min, pet Age. pets['Age (years)'].idxmax() returns the index where the max age is found. Correspondingly pets['Age (years)'].idxmin() returns the index where the min age is found.*\n",
    "\n",
    "\n",
    "Once we know the index for a row, we can easily view it to learn more about the data in that row, and decide if it seems reasonable.\n",
    "\n",
    "![coin df 13](../_images/Module3-Unit4-image13.png)\n",
    "\n",
    "*Demonstration of how to access the 5th row on the pets DataFrame (we start counting from 0). We can use the loc property to access a the information associated to a row number. In Python we start counting from 0, so that the first row has index 0, second row index 1, ..., fifth row has index 4. To use this code, call pets.loc[4] to return values associated to each column for pet in fifth row.*\n",
    "\n",
    "### 🏁 Activity: \n",
    "\n",
    "Using your Jupyter notebook, find the pet that took the longest to adopt. Is there anything interesting about this pet?\n",
    "\n",
    "Also check, which pet had the most legs? What kind of animal is it?\n",
    "\n",
    "\n",
    "### Other methods for cleaning and organizing data\n",
    "\n",
    "There are many other methods for finding and addressing errors in DataFrames beyond what we have explored in this unit.\n",
    "\n",
    "As you become more comfortable using DataFrames in Jupyter notebooks, we encourage you to explore the resource below for more information about what they can do.\n",
    "\n",
    "#### Explore\n",
    "\n",
    ">This reference page provides an overview of the essential functionality common to the pandas data structures. [Essential basic functionality](https://pandas.pydata.org/pandas-docs/stable/user_guide/basics.html)\n",
    "\n",
    "This reference page provides an overview of the essential functionality common to the pandas data structures.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "So far we've seen a variety of techniques for manipulating **quantitative data** in a DataFrame, like counts and measurements.\n",
    "\n",
    "In the next unit, we'll explore methods for manipulating **qualitative data,** like names, labels, and descriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55e408c-db2a-42bb-9426-fd5cf38946a4",
   "metadata": {},
   "source": [
    "[![Callysto.ca License](https://github.com/callysto/curriculum-notebooks/blob/master/callysto-notebook-banner-bottom.jpg?raw=true)](https://github.com/callysto/curriculum-notebooks/blob/master/LICENSE.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
